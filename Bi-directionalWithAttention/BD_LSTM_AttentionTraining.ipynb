{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# # DeepFix : Deep learning for automatically fixing single-line syntax errors in C programs (using Encoder-Decoder-Attention model approach.) "
   ],
   "metadata": {
    "id": "df47eCT8961F"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#from keras.layers import Input, LSTM, Dense\r\n",
    "from tensorflow.keras.models import Model \r\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense , Bidirectional ,  Concatenate\r\n",
    "from tensorflow.keras.preprocessing.text import one_hot\r\n",
    "from tensorflow.keras.layers import Embedding\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from operator import itemgetter\r\n",
    "import pandas as pd\r\n",
    "import pickle \r\n",
    "import tensorflow as tf\r\n",
    "import numpy as np\r\n",
    "import csv\r\n",
    "from BahdanauAttention import AttentionLayer\r\n",
    "from customfunction import text2sequence , sequence2tokenization , encoder_decoder_data\r\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "c0b45f7c-c38d-466f-a5f4-375f09af651d"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data & Build vocabulary on traning data ---\r\n",
    "\r\n",
    "Dataset Description :\r\n",
    "\r\n",
    "Each row of the dataset is buggy C program line and 'target' C line which represents fixed C program line."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data=pd.read_csv('G:/IISc/2nd-semester/ASE with ML/Assignment/DeepFixLite/train.csv')\r\n",
    "\r\n",
    "input_texts = data['sourceLineTokens']\r\n",
    "target_texts = data['targetLineTokens']\r\n",
    "\r\n",
    "input_lines , target_lines , token2count = text2sequence(input_texts , target_texts)"
   ],
   "outputs": [],
   "metadata": {
    "id": "e8c5a33e-fc53-4cca-aeef-0028b69d2ad2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(1)Setting parameters such as sentence length, vocabulory size = num_unique_tokens.\r\n",
    "\r\n",
    "(2) Select top 1000 most frequent words and construct vocabulary only for that many words. \r\n",
    "\r\n",
    "(3) Download Dictionary."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "k=1000 # select top 1000 words(most frequent)\r\n",
    "sent_length=70\r\n",
    "num_unique_tokens = k + 4\r\n",
    "num_samples = len(input_lines)\r\n",
    "\r\n",
    "token_with_count = dict(sorted(token2count.items(), key = itemgetter(1), reverse = True)[:k])\r\n",
    "token2index = {\"PAD\":0, \"SOS\":1, \"EOS\":2, \"OOV\":3}\r\n",
    "index2token = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\", 3: \"OOV\"}\r\n",
    "num_count = 4\r\n",
    "for i in token_with_count:\r\n",
    "  token2index[i] = num_count\r\n",
    "  index2token[num_count] = i\r\n",
    "  num_count += 1\r\n",
    "\r\n",
    "# pickle_out1 = open(\"token2index.pickle\" , \"wb\")\r\n",
    "# pickle_out2 = open(\"index2token.pickle\" , \"wb\")\r\n",
    "\r\n",
    "# pickle.dump(token2index , pickle_out1)\r\n",
    "# pickle.dump(index2token , pickle_out2)\r\n",
    "\r\n",
    "# pickle_out1.close()\r\n",
    "# pickle_out2.close()"
   ],
   "outputs": [],
   "metadata": {
    "id": "40397cd7-d8ec-41f1-837f-a3bdeeae704a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "max_encoder_seq_length = max([len(eval(item)) for item in input_lines]) #154\r\n",
    "max_decoder_seq_length = max([len(eval(item)) for item in target_lines]) #169\r\n",
    "\r\n",
    "print(\"size of the original vocabulary =\",len(token2count))\r\n",
    "print(\"size of the updated vocabulary =\",len(token_with_count))\r\n",
    "print(\"max_encoder_seq_length =\",max_encoder_seq_length)\r\n",
    "print(\"max_decoder_seq_length =\",max_decoder_seq_length)\r\n",
    "print(\"number of samples =\",num_samples )\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "size of the original vocabulary = 5205\n",
      "size of the updated vocabulary = 1000\n",
      "max_encoder_seq_length = 154\n",
      "max_decoder_seq_length = 169\n",
      "number of samples = 14643\n"
     ]
    }
   ],
   "metadata": {
    "id": "15104303-ee91-4eff-bc9c-ed47916f4481"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generating fixed size sequences which can be given input to neural networks\r\n",
    "\r\n",
    "(1) Tokenise input sequence \r\n",
    "\r\n",
    "(2) Add padding to make equal size sequence  \r\n",
    "\r\n",
    "Above two functionalities implemented in sequence2tokenization function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "padded_input_texts = sequence2tokenization(input_lines , token2index , sent_length)\r\n",
    "padded_target_texts = sequence2tokenization(target_lines , token2index , sent_length)\r\n",
    "\r\n",
    "print(padded_input_texts[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 1 21  4 82 48  8 42 11 17  5  2  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "metadata": {
    "id": "4b74e168-0c03-4ab3-8147-e4efe7f35b33"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Encoder Input data, decoder input data are inputs that need to be given to LSTM's networks for encoding and decoding."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "encoder_input_data , decoder_input_data , decoder_target_data = encoder_decoder_data(padded_input_texts , padded_target_texts ,num_samples ,sent_length ,num_unique_tokens )\r\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "475ba93e-2bd7-4b60-a23d-e72529aed56c"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre_process the validation data(same step as we did previously on training data) for parameter tunning."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "valid_data=pd.read_csv('G:/IISc/2nd-semester/ASE with ML/Assignment/DeepFixLite/valid_complete.csv')\r\n",
    "\r\n",
    "input_valid_texts = valid_data['sourceLineTokens']\r\n",
    "target_valid_texts = valid_data['targetLineTokens']\r\n",
    "num_valid_samples = len(input_valid_texts)\r\n",
    "padded_input_valid_texts = sequence2tokenization(input_valid_texts , token2index , sent_length)\r\n",
    "padded_target_valid_texts = sequence2tokenization(target_valid_texts , token2index , sent_length)\r\n",
    "\r\n",
    "encoder_input_valid_data ,decoder_input_valid_data ,decoder_target_valid_data = encoder_decoder_data(padded_input_valid_texts , padded_target_valid_texts ,num_valid_samples ,sent_length ,num_unique_tokens )\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "93e0d31a-4974-4c3d-92b0-78655700ecfe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Design Encoder-decoder-Attention model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "latent_dim=256\r\n",
    "batch_size=64\r\n",
    "epochs = 10\r\n",
    "emb_size = 50\r\n",
    "\r\n",
    "# Encoder \r\n",
    "\r\n",
    "encoder_inputs = Input(shape=(sent_length,)) \r\n",
    "enc_emb = Embedding(num_unique_tokens, 1024)(encoder_inputs)\r\n",
    "\r\n",
    "# Bidirectional lstm layer\r\n",
    "enc_lstm1 = Bidirectional(LSTM(256,return_sequences=True,return_state=True))\r\n",
    "encoder_outputs1, forw_state_h, forw_state_c, back_state_h, back_state_c = enc_lstm1(enc_emb)\r\n",
    "\r\n",
    "final_enc_h = Concatenate()([forw_state_h,back_state_h])\r\n",
    "final_enc_c = Concatenate()([forw_state_c,back_state_c])\r\n",
    "\r\n",
    "encoder_states =[final_enc_h, final_enc_c]\r\n",
    "\r\n",
    "# Set up the decoder. \r\n",
    "decoder_inputs = Input(shape=(None,)) \r\n",
    "dec_emb_layer = Embedding(num_unique_tokens, 1024) \r\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\r\n",
    "#LSTM using encoder_states as initial state\r\n",
    "decoder_lstm = LSTM(512, return_sequences=True, return_state=True) \r\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\r\n",
    "\r\n",
    "#Attention Layer\r\n",
    "attention_layer = AttentionLayer()\r\n",
    "attention_result, attention_weights = attention_layer([encoder_outputs1, decoder_outputs])\r\n",
    "\r\n",
    "# Concat attention output and decoder LSTM output \r\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention_result])\r\n",
    "\r\n",
    "#Dense layer\r\n",
    "decoder_dense = Dense(num_unique_tokens, activation='softmax')\r\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\r\n",
    "\r\n",
    "\r\n",
    "# Define the model\r\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ],
   "outputs": [],
   "metadata": {
    "id": "571de098-9471-46c3-85df-9e8a330c0b14"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 70, 1024)     1028096     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 70, 512), (N 2623488     embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 1024)   1028096     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 512),  3147776     embedding_3[0][0]                \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_1 (AttentionLay ((None, None, 512),  524800      bidirectional_1[0][0]            \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 1024)   0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 1004)   1029100     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 9,381,356\n",
      "Trainable params: 9,381,356\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')"
   ],
   "outputs": [],
   "metadata": {
    "id": "bb955cbf-fd5c-4c9a-8ade-3ba801a9fe42"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "history1= model.fit(\r\n",
    "    [encoder_input_data, decoder_input_data],decoder_target_data,\r\n",
    "    batch_size=batch_size,\r\n",
    "    epochs=3,\r\n",
    "    #validation_split=0.2,\r\n",
    "    validation_data=([encoder_input_valid_data,decoder_input_valid_data],decoder_target_valid_data)\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "229/229 [==============================] - 2519s 11s/step - loss: 0.4684 - accuracy: 0.9020 - val_loss: 0.3322 - val_accuracy: 0.9258\n",
      "Epoch 2/3\n",
      "229/229 [==============================] - 2373s 10s/step - loss: 0.2876 - accuracy: 0.9365 - val_loss: 0.2545 - val_accuracy: 0.9455\n",
      "Epoch 3/3\n",
      "229/229 [==============================] - 2537s 11s/step - loss: 0.2096 - accuracy: 0.9521 - val_loss: 0.1888 - val_accuracy: 0.9580\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29a3ac8d-6db9-4620-acea-4ffdb2c4d3ce",
    "outputId": "905fe615-72ea-4a7e-cf9e-b53c7aab6edb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "tf.keras.models.save_model(model, \"G:/IISc/2nd-semester/ASE with ML/Assignment/DeepFixLite/Attention_model\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: G:/IISc/2nd-semester/ASE with ML/Assignment/DeepFixLite/Attention_model\\assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Assets written to: G:/IISc/2nd-semester/ASE with ML/Assignment/DeepFixLite/Attention_model\\assets\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ce2e0fd8-9cb2-47c3-b7b8-7b4f94c9332f"
   ],
   "name": "Training_Encoder_Decoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "interpreter": {
   "hash": "efa960d91a83404a0e734f3d71ae38205449cca1b61855dfb07d190bd7f56433"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}